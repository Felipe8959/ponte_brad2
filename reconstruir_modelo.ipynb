{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eaac824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Copiado] config.json\n",
      "[Reconstruindo] model.safetensors...\n",
      "  -> Uniu: model.safetensors.part001\n",
      "  -> Uniu: model.safetensors.part002\n",
      "  -> Uniu: model.safetensors.part003\n",
      "  -> Uniu: model.safetensors.part004\n",
      "  -> Uniu: model.safetensors.part005\n",
      "  -> Uniu: model.safetensors.part006\n",
      "  -> Uniu: model.safetensors.part007\n",
      "  -> Uniu: model.safetensors.part008\n",
      "  -> Uniu: model.safetensors.part009\n",
      "  -> Uniu: model.safetensors.part010\n",
      "  -> Uniu: model.safetensors.part011\n",
      "  -> Uniu: model.safetensors.part012\n",
      "  -> Uniu: model.safetensors.part013\n",
      "  -> Uniu: model.safetensors.part014\n",
      "  -> Uniu: model.safetensors.part015\n",
      "  -> Uniu: model.safetensors.part016\n",
      "  -> Uniu: model.safetensors.part017\n",
      "  -> Uniu: model.safetensors.part018\n",
      "  -> Uniu: model.safetensors.part019\n",
      "  -> Uniu: model.safetensors.part020\n",
      "  -> Uniu: model.safetensors.part021\n",
      "[Copiado] special_tokens_map.json\n",
      "[Copiado] tokenizer.json\n",
      "[Copiado] tokenizer_config.json\n",
      "[Copiado] vocab.txt\n",
      "\n",
      "Sucesso! O modelo está em 'bert_final'.\n",
      "Use o comando abaixo para carregar:\n",
      "model = AutoModel.from_pretrained('./bert_final')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "# --- CONFIGURAÇÕES ---\n",
    "# Nome da pasta que você baixou do GitHub (onde estão as partes)\n",
    "INPUT_DIR = \"bert_upload_github\" \n",
    "# Nome da pasta onde o modelo pronto ficará\n",
    "OUTPUT_DIR = \"bert_final\"\n",
    "\n",
    "def join_files(filename_base, source_dir, dest_dir):\n",
    "    \"\"\"Reconstroi arquivos particionados.\"\"\"\n",
    "    # Procura por todas as partes (ex: pytorch_model.bin.part*)\n",
    "    pattern = os.path.join(source_dir, f\"{filename_base}.part*\")\n",
    "    parts = sorted(glob.glob(pattern))\n",
    "    \n",
    "    output_path = os.path.join(dest_dir, filename_base)\n",
    "    \n",
    "    if not parts:\n",
    "        # Se não tem partes, verifica se o arquivo existe inteiro (caso dos arquivos pequenos)\n",
    "        original_file = os.path.join(source_dir, filename_base)\n",
    "        if os.path.exists(original_file):\n",
    "            shutil.copy2(original_file, output_path)\n",
    "            print(f\"[Copiado] {filename_base}\")\n",
    "        return\n",
    "\n",
    "    print(f\"[Reconstruindo] {filename_base}...\")\n",
    "    with open(output_path, 'wb') as outfile:\n",
    "        for part in parts:\n",
    "            with open(part, 'rb') as infile:\n",
    "                outfile.write(infile.read())\n",
    "            print(f\"  -> Uniu: {os.path.basename(part)}\")\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(INPUT_DIR):\n",
    "        print(f\"Erro: Pasta de entrada '{INPUT_DIR}' não encontrada.\")\n",
    "        return\n",
    "\n",
    "    if os.path.exists(OUTPUT_DIR):\n",
    "        shutil.rmtree(OUTPUT_DIR)\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "    # Identificar quais são os arquivos originais baseados nos nomes das partes\n",
    "    # ou arquivos soltos\n",
    "    processed_files = set()\n",
    "    \n",
    "    files_in_dir = os.listdir(INPUT_DIR)\n",
    "    \n",
    "    for file in files_in_dir:\n",
    "        # Remove a extensão .partXXX para pegar o nome base\n",
    "        if \".part\" in file:\n",
    "            base_name = file.split(\".part\")[0]\n",
    "        else:\n",
    "            base_name = file\n",
    "            \n",
    "        if base_name not in processed_files:\n",
    "            join_files(base_name, INPUT_DIR, OUTPUT_DIR)\n",
    "            processed_files.add(base_name)\n",
    "\n",
    "    print(f\"\\nSucesso! O modelo está em '{OUTPUT_DIR}'.\")\n",
    "    print(\"Use o comando abaixo para carregar:\")\n",
    "    print(f\"model = AutoModel.from_pretrained('./{OUTPUT_DIR}')\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
