{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd05144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm  # barra de progresso\n",
    "\n",
    "### CONFIGURAÇÕES\n",
    "MODEL_PATH = \"./bert_final\" #caminho do modelo local\n",
    "BATCH_SIZE = 32 # qtd de textos processados por vez pelo bert\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" # se não achar gpu, usa cpu\n",
    "\n",
    "print(f\"OK dispositivo detectado: {DEVICE.upper()}\")\n",
    "print(f\"OK carregando modelo de: {MODEL_PATH} ...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH) # carrega tokenizer\n",
    "model = AutoModel.from_pretrained(MODEL_PATH).to(DEVICE) # carrega modelo bert\n",
    "\n",
    "# coloca o modelo em modo de avaliação (eval)\n",
    "# isso desliga o cálculo de gradientes e camadas de dropout\n",
    "# economiza memória e deixa o processo mais rápido\n",
    "model.eval()\n",
    "\n",
    "print(\"Modelo carregado\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fa41e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARREGAMENTO DOS DADOS\n",
    "print(\"Carregando dados para treinamento e teste...\")\n",
    "\n",
    "# DADOS HISTÓRICOS (para aprendizado)\n",
    "# n exemplos passados\n",
    "# A coluna 'TARGET_FULL' concatena os 3 níveis para o modelo aprender tudo junto\n",
    "dados_reais = [\n",
    "    # --- FAMÍLIA: CARTÕES ---\n",
    "    (\"Não reconheço essa compra na padaria\", \"Cartão | Contestação | Compra Não Reconhecida\"),\n",
    "    (\"Apareceu uma assinatura de streaming que eu cancelei\", \"Cartão | Contestação | Compra Recorrente\"),\n",
    "    (\"Clonaram meu cartão, tem gastos em dolar\", \"Cartão | Contestação | Fraude Externa\"),\n",
    "    (\"Minha fatura veio com anuidade sendo que era isento\", \"Cartão | Tarifas | Cobrança de Anuidade\"),\n",
    "    (\"Quero aumentar meu limite para viajar\", \"Cartão | Limite | Análise de Crédito\"),\n",
    "    (\"O cartão chegou mas a senha não funciona\", \"Cartão | Entrega | Desbloqueio/Senha\"),\n",
    "    (\"Recebi um cartão que eu nunca pedi\", \"Cartão | Contratação | Cartão não Solicitado\"),\n",
    "\n",
    "    # --- FAMÍLIA: CONTA CORRENTE / PIX ---\n",
    "    (\"Meu pix saiu da conta mas a loja diz que não recebeu\", \"Conta Corrente | Pix | Falha Tecnológica\"),\n",
    "    (\"Fiz um pix errado, quero o dinheiro de volta\", \"Conta Corrente | Pix | Devolução (MED)\"),\n",
    "    (\"Tem uma tarifa de cesta de serviços que não contratei\", \"Conta Corrente | Tarifas | Pacote de Serviços\"),\n",
    "    (\"Não consigo acessar minha conta pelo celular\", \"Canais Digitais | App | Erro de Acesso\"),\n",
    "    (\"O app fecha sozinho quando tento pagar boleto\", \"Canais Digitais | App | Instabilidade\"),\n",
    "    (\"Quero encerrar minha conta, vou mudar de banco\", \"Conta Corrente | Encerramento | Cancelamento Voluntário\"),\n",
    "    (\"Vocês bloquearam minha conta sem avisar\", \"Conta Corrente | Bloqueio | Segurança/Compliance\"),\n",
    "\n",
    "    # --- FAMÍLIA: EMPRÉSTIMOS / COBRANÇA ---\n",
    "    (\"Os juros desse empréstimo estão abusivos\", \"Empréstimo | Pessoal | Revisão de Juros\"),\n",
    "    (\"Quero quitar meu financiamento de carro antecipado\", \"Empréstimo | Veículos | Amortização\"),\n",
    "    (\"Estou recebendo ligações de cobrança o dia todo\", \"Cobrança | Abordagem | Excesso de Ligações\"),\n",
    "    (\"Quero renegociar minha dívida, estou desempregado\", \"Cobrança | Renegociação | Acordo\"),\n",
    "    (\"Descontaram a parcela do emprestimo duas vezes\", \"Empréstimo | Consignado | Desconto Indevido\"),\n",
    "\n",
    "    # --- FAMÍLIA: ATENDIMENTO ---\n",
    "    (\"O gerente foi extremamente grosso comigo\", \"Atendimento | Agência | Postura do Funcionário\"),\n",
    "    (\"Fiquei 2 horas na fila esperando atendimento\", \"Atendimento | Agência | Tempo de Espera\"),\n",
    "    (\"O SAC desliga a chamada na minha cara\", \"Atendimento | SAC | Qualidade da Ligação\"),\n",
    "    (\"Ninguém resolve meu problema, ficam jogando de um para o outro\", \"Atendimento | Geral | Falta de Resolução\"),\n",
    "\n",
    "    # --- FAMÍLIA: INVESTIMENTOS ---\n",
    "    (\"Quero resgatar meu dinheiro da poupança e não consigo\", \"Investimentos | Poupança | Resgate\"),\n",
    "    (\"Meu assessor de investimentos me recomendou algo que deu prejuízo\", \"Investimentos | Assessoria | Suitability\"),\n",
    "    (\"Não recebi o informe de rendimentos para o imposto de renda\", \"Investimentos | Documentação | Informe de Rendimentos\")\n",
    "]\n",
    "\n",
    "# Criando o DataFrame\n",
    "df_historico = pd.DataFrame(dados_reais, columns=['TEXTO_CLIENTE', 'TARGET_FULL'])\n",
    "\n",
    "# DADOS NOVOS (para classificar)\n",
    "# Estes são os 40.000 que você quer classificar. Simulando 5 exemplos aqui.\n",
    "df_novos = pd.DataFrame({\n",
    "    'ID_MANIFESTACAO': range(1001, 1016), # IDs fictícios de 1001 a 1015\n",
    "    'TEXTO_CLIENTE': [\n",
    "        # --- Variações de CARTÃO (Treino: \"Não reconheço compra\") ---\n",
    "        \"Apareceu uma cobrança da Netflix na minha fatura que eu não assinei.\",\n",
    "        \"Tem um débito de 500 reais do Mercado Livre que é fraude.\",\n",
    "        \"Veio uma compra internacional que desconheço.\",\n",
    "\n",
    "        # --- Variações de PIX (Treino: \"Pix saiu mas não chegou\") ---\n",
    "        \"Fiz uma transferência instantânea pro meu irmão e o dinheiro sumiu.\",\n",
    "        \"O comprovante do pix saiu, mas o destinatário diz que não recebeu nada.\",\n",
    "        \"Erro na transação, debitou o saldo mas não completou o envio.\",\n",
    "\n",
    "        # --- Variações de CANCELAMENTO (Treino: \"Quero cancelar conta\") ---\n",
    "        \"Gostaria de encerrar meu relacionamento com este banco.\",\n",
    "        \"Desejo fechar minha conta, não uso mais.\",\n",
    "        \"Qual o procedimento para o encerramento da conta corrente?\",\n",
    "\n",
    "        # --- Variações de ATENDIMENTO (Treino: \"Gerente mal educado\") ---\n",
    "        \"O atendente do caixa foi extremamente grosso comigo hoje.\",\n",
    "        \"Fui destratado na agência da Avenida Paulista.\",\n",
    "        \"Falta de respeito por parte dos funcionários da agência.\",\n",
    "\n",
    "        # --- Variações de JUROS (Treino: \"Juros abusivos\") ---\n",
    "        \"A taxa que vocês estão cobrando no cheque especial é um absurdo.\",\n",
    "        \"Descontaram uns encargos da minha conta que eu não concordo.\",\n",
    "        \"O valor dos juros rotativos está muito alto este mês.\",\n",
    "        \n",
    "        # --- CASO AMBÍGUO (Teste de Stress) ---\n",
    "        \"Vocês estão roubando meu dinheiro com essas taxas no cartão.\" \n",
    "        # (Mistura \"Cartão\" com \"Taxas/Juros\" - vamos ver o que ele decide)\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a34ca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNÇÃO DE GERAÇÃO DE VETORES (EMBEDDINGS)\n",
    "def generate_embeddings_batched(texts, tokenizer, model, batch_size=32):\n",
    "    \"\"\"\n",
    "    Função que recebe uma lista de textos e retorna uma matriz numérica\n",
    "    Usa processamento em batches para não estourar a memória RAM\n",
    "    \"\"\"\n",
    "    all_embeddings = []\n",
    "    \n",
    "    # barra de progresso no terminal\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Vetorizando textos\"):\n",
    "        \n",
    "        # pega uma fatia da lista de textos (ex: do 0 ao 32, do 32 ao 64...)\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        \n",
    "        # 1. Tokenização: Prepara o texto para o BERT\n",
    "        # padding=True: Preenche frases curtas para ficarem do mesmo tamanho\n",
    "        # truncation=True: Corta frases maiores que 128 tokens (limite comum)\n",
    "        inputs = tokenizer(\n",
    "            batch_texts, \n",
    "            padding=True, \n",
    "            truncation=True, \n",
    "            max_length=128, \n",
    "            return_tensors=\"pt\" # retorna tensores do PyTorch\n",
    "        ).to(DEVICE) # move os dados para CPU ou GPU\n",
    "        \n",
    "        # 2. Inferência: O texto passa pela rede neural\n",
    "        with torch.no_grad(): # Desabilita cálculo de treino (economia gigantesca de RAM)\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        # 3. Pooling: Transformar o resultado complexo em um único vetor por frase\n",
    "        # Pegamos a média (mean) da última camada escondida (last_hidden_state)\n",
    "        # .cpu().numpy() traz os dados da placa de vídeo de volta para a memória RAM normal\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "        \n",
    "        # Adiciona o resultado parcial na lista final\n",
    "        all_embeddings.append(embeddings)\n",
    "        \n",
    "    # junta todos os pedaços em uma única matriz numpy gigante\n",
    "    return np.vstack(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a14e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TREINAMENTO DO MODELO (supervisionado)\n",
    "print(f\"\\n[Fase 1] Processando {len(df_historico)} registros do histórico...\")\n",
    "\n",
    "# vetores para o histórico x\n",
    "X_historico = generate_embeddings_batched(\n",
    "    df_historico['TEXTO_CLIENTE'].tolist(), \n",
    "    tokenizer, \n",
    "    model, \n",
    "    BATCH_SIZE\n",
    ")\n",
    "\n",
    "# target y\n",
    "y_historico = df_historico['TARGET_FULL']\n",
    "\n",
    "# treino e validação\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_historico, y_historico, test_size=0.2, random_state=42)\n",
    "\n",
    "# cria e treina o classificador (MLP - Multi Layer Perceptron)\n",
    "# esta é a rede neural \"leve\" que vai aprender as regras do banco\n",
    "print(\"\\n[Fase 2] Treinando o classificador baseada no histórico...\")\n",
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(256, 128), # camadas ocultas (neurônios)\n",
    "    max_iter=300,                  # máximo de épocas de treino\n",
    "    random_state=42,               # semente para reprodutibilidade\n",
    "    verbose=True                   # mostra o log de loss no terminal\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train) # treinamento\n",
    "\n",
    "# avaliação\n",
    "print(\"\\n--- Validação do Modelo (Acurácia) ---\")\n",
    "print(f\"Acurácia nos dados de teste: {clf.score(X_val, y_val):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b696e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDIÇÃO NOS DADOS NOVOS (TOP 3)\n",
    "print(f\"\\n[Fase 3] Classificando {len(df_novos)} novos casos...\")\n",
    "\n",
    "# vetores para os dados novos\n",
    "X_novos = generate_embeddings_batched(\n",
    "    df_novos['TEXTO_CLIENTE'].tolist(), \n",
    "    tokenizer, \n",
    "    model, \n",
    "    BATCH_SIZE\n",
    ")\n",
    "\n",
    "# obtém as probabilidades de TODAS as classes para cada texto\n",
    "# retorna uma matriz onde linhas = textos e colunas = probabilidade de cada categoria\n",
    "print(\"Calculando probabilidades...\")\n",
    "probas = clf.predict_proba(X_novos)\n",
    "\n",
    "# lista de nomes das classes (na ordem das colunas da matriz probas)\n",
    "classes = clf.classes_\n",
    "\n",
    "# llistas para armazenar o resultado final\n",
    "top1_label, top1_score = [], []\n",
    "top2_label, top2_score = [], []\n",
    "top3_label, top3_score = [], []\n",
    "\n",
    "# loop para processar cada linha e extrair o Top 3\n",
    "for i in tqdm(range(len(probas)), desc=\"Extraindo Top 3\"):\n",
    "    row_probas = probas[i]\n",
    "    \n",
    "    # argsort retorna os ÍNDICES ordenados do menor para o maior\n",
    "    # Pegamos os últimos 3 ([-3:]) e invertemos ([: : -1]) para ter: 1º, 2º, 3º\n",
    "    top_indices = np.argsort(row_probas)[-3:][::-1]\n",
    "    \n",
    "    # 1º lugar\n",
    "    idx1 = top_indices[0]\n",
    "    top1_label.append(classes[idx1])\n",
    "    top1_score.append(row_probas[idx1])\n",
    "    \n",
    "    # 2º lugar (Verifica se existe, caso haja menos de 2 categorias no treino)\n",
    "    if len(top_indices) > 1:\n",
    "        idx2 = top_indices[1]\n",
    "        top2_label.append(classes[idx2])\n",
    "        top2_score.append(row_probas[idx2])\n",
    "    else:\n",
    "        top2_label.append(None)\n",
    "        top2_score.append(0.0)\n",
    "        \n",
    "    # 3º lugar\n",
    "    if len(top_indices) > 2:\n",
    "        idx3 = top_indices[2]\n",
    "        top3_label.append(classes[idx3])\n",
    "        top3_score.append(row_probas[idx3])\n",
    "    else:\n",
    "        top3_label.append(None)\n",
    "        top3_score.append(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a11c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATAFRAME FINAL\n",
    "\n",
    "# Adiciona as colunas no dataframe original de novos dados\n",
    "df_novos['RECOMENDACAO_1'] = top1_label\n",
    "df_novos['SCORE_1'] = top1_score\n",
    "\n",
    "df_novos['RECOMENDACAO_2'] = top2_label\n",
    "df_novos['SCORE_2'] = top2_score\n",
    "\n",
    "df_novos['RECOMENDACAO_3'] = top3_label\n",
    "df_novos['SCORE_3'] = top3_score\n",
    "\n",
    "print(\"\\n--- PROCESSO CONCLUÍDO! ---\")\n",
    "print(\"Visualizando as primeiras linhas do resultado:\")\n",
    "\n",
    "# Mostra as colunas principais\n",
    "cols = ['TEXTO_CLIENTE', 'RECOMENDACAO_1', 'SCORE_1', 'RECOMENDACAO_2', 'SCORE_2']\n",
    "df_novos[cols].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
